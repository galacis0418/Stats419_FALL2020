denzel = IMDB.searchPersonName("Denzel* Washington")
myWill.df = will.search$movies.50
WillRatings = myWill.df$metacritic
myDenzel.df = denzel$movies.50
denzelTop = myDenzel.df
DMovieRatings = myDenzel.df$metacritic
WGross = myWill.df$millions
DGross = myDenzel.df$millions
normalDiagnosticPlot(WGross)
knitr::opts_chunk$set(echo = TRUE)
library(devtools);
library(humanVerseWSU);
path.github = "https://raw.githubusercontent.com/MonteShaffer/humanVerseWSU/master/";
include.me = paste0(path.github, "misc/functions-nlp.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-str.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-stack.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-pos.R");
source_url( include.me );
include.me = paste0(path.github, "humanVerseWSU/R/functions-encryption.R");
source_url( include.me );
include.me = paste0(path.github,"misc/functions-project-measure.R");
source_url( include.me);
path.to.nascent = "C:/Users/Alexander Nevsky/Dropbox/WSU-419/Fall 2020/__student_access__/unit_02_confirmatory_data_analysis/nascent/";
folder.nlp = "nlp/";
path.to.nlp = paste0(path.to.nascent, folder.nlp);
###### UPDATES TO dataframe subset function ######
# inflation adjustments for NA ... and improvements on subsetting
include.me = paste0(path.github, "humanVerseWSU/R/functions-dataframe.R");
source_url( include.me );
include.me = paste0(path.github, "humanVerseWSU/R/functions-inflation.R");
source_url( include.me );
# library(devtools);
# install_github("MonteShaffer/imdb/imdb"); # choose #3 to humanVerseWSU
# detach(package:imdb);
library(imdb);
packageVersion("imdb");  # ‘0.1.1’
# ?loadDataIMDB
install_github("MonteShaffer/imdb/imdb")
imdb::loadDataIMDB();
names(imdb.data);
humanVerseWSU::loadInflationData();
library(KernSmooth)
normalDiagnosticPlot = function(x,  normalityTest=TRUE,
showDensity=TRUE,
showNormal=TRUE,
showSDs=FALSE,
showAxis=TRUE
)
{
xx = na.omit(x);
x.stats = doStatsSummary(x);
# x.table = table(x);
# library(KernSmooth); # install.packages("KernSmooth", dependencies=TRUE);
# bin.count = dpih(xx);
# mybreaks = 100 * bin.count;
mxlim = c(x.stats$mean - 3.5 * x.stats$sd ,
x.stats$mean + 3.5 * x.stats$sd );
h = hist(xx, breaks="Sturges", plot=F);
mylim = c(0, max(h$counts));
myMain = paste0(  "Histogram (mean: ",
round(x.stats$mean,digits=3),
", sd: ",
round(x.stats$sd,digits=3),
")"
);
mxlab = "";
if(normalityTest)
{
isNormal = NULL;
if(x.stats$shapiro.is.normal$`0.10`) { isNormal = 0.10; }
if(x.stats$shapiro.is.normal$`0.05`) { isNormal = 0.05; }
if(x.stats$shapiro.is.normal$`0.01`) { isNormal = 0.01; }
isNormalResult = FALSE;
if(!is.null(isNormal)) { isNormalResult = TRUE;}
if(is.null(isNormal)) { isNormal = 0.05;}
mxlab = paste0("Shapiro Normality test at (alpha = ",
isNormal, ") is ... ",isNormalResult);
}
### Histogram
hist(xx, breaks="Sturges",  xlim=mxlim, ylim=mylim,
xlab=mxlab, xaxt='n', main=myMain);
if(showDensity)
{
par(new=T); # overlay
### Density Plot (remember first reading?)
plot( density(xx, kernel="epanechnikov") ,
xlim=mxlim,
main="",
xlab="",
ylab="",
xaxt='n',
yaxt='n'
);
}
if(showNormal)
{
par(new=T); # overlay
### Normal Curve
xt = seq(-3.5,3.5, length=100);
yt = dnorm(xt);
plot( xt, yt,
type="l",
lwd=2,
col = "red",
axes=F,
xlab="",
ylab=""
);
}
if(showSDs)
{
### vertical lines at sd's of data ...
abline(v=x.stats$mean,lwd=4,col="blue");
abline(v=x.stats$mean - 1 * x.stats$sd , col="green",lwd=3);
abline(v=x.stats$mean + 1 * x.stats$sd , col="green",lwd=3);
abline(v=x.stats$mean - 2 * x.stats$sd , col="green",lwd=2);
abline(v=x.stats$mean + 2 * x.stats$sd , col="green",lwd=2);
abline(v=x.stats$mean - 3 * x.stats$sd , col="green",lwd=1);
abline(v=x.stats$mean + 3 * x.stats$sd , col="green",lwd=1);
}
if(showAxis)
{
### axis labels showing the ability to use expression
axis(1, at = -3:3, labels = c( expression("-3"~hat(sigma) ), expression("-2"~sigma ), expression("-1"~hat(s) ), expression(bar(x)), expression("1"~hat(s) ), "2s", c( expression("3"~hat(sigma) ))) );
#axis(1, at = -3:3, labels = c("-3s", "-2s", "-1s", "hat(mu)", "1s", "2s", "3s"))
}
}
library(dplyr)
will = IMDB.searchPersonName("Will* Smith*");
denzel = IMDB.searchPersonName("Denzel* Washington")
myWill.df = will.search$movies.50
WillRatings = myWill.df$metacritic
myDenzel.df = denzel$movies.50
denzelTop = myDenzel.df
DMovieRatings = myDenzel.df$metacritic
WGross = myWill.df$millions
DGross = myDenzel.df$millions
normalDiagnosticPlot(WGross)
library(dplyr)
will = IMDB.searchPersonName("Will* Smith*");
denzel = IMDB.searchPersonName("Denzel* Washington")
myWill.df = will.search$movies.50
WillRatings = myWill.df$metacritic
myDenzel.df = denzel$movies.50
denzelTop = myDenzel.df
DMovieRatings = myDenzel.df$metacritic
WGross = myWill.df$millions
DGross = myDenzel.df$millions
normalDiagnosticPlot(WGross)
library(dplyr)
will.nmid = "nm0000226";
will.movies = IMDB.getMoviesForPerson(will.nmid);
will.n = nrow(will.movies);
denzel.nmid = "nm0000243";
denzel.movies = IMDB.getMoviesForPerson(denzel.nmid);
denzel.n = nrow(denzel.movies);
#will = IMDB.searchPersonName("Will* Smith*");
#denzel = IMDB.searchPersonName("Denzel* Washington")
myWill.df = will.search$movies.50
WillRatings = myWill.df$metacritic
myDenzel.df = denzel$movies.50
denzelTop = myDenzel.df
DMovieRatings = myDenzel.df$metacritic
WGross = myWill.df$millions
DGross = myDenzel.df$millions
normalDiagnosticPlot(WGross)
View(will.movies)
library(dplyr)
will.nmid = "nm0000226";
will.movies = IMDB.getMoviesForPerson(will.nmid);
will.n = nrow(will.movies);
denzel.nmid = "nm0000243";
denzel.movies = IMDB.getMoviesForPerson(denzel.nmid);
denzel.n = nrow(denzel.movies);
#will = IMDB.searchPersonName("Will* Smith*");
#denzel = IMDB.searchPersonName("Denzel* Washington")
myWill.df = will.movies
WillRatings = myWill.df$metacritic
myDenzel.df = denzel.movies
denzelTop = myDenzel.df
DMovieRatings = myDenzel.df$metacritic
WGross = myWill.df$millions
DGross = myDenzel.df$millions
normalDiagnosticPlot(WGross)
normalDiagnosticPlot(DGross)
hist(WGross, main = "Histogram of Will Smith movie Grosses")
hist(DGross, main = "Histogram of Denzels movie Grosses")
plot(WGross, DGross)
library(dplyr)
will.nmid = "nm0000226";
will.movies = IMDB.getMoviesForPerson(will.nmid);
will.n = nrow(will.movies);
denzel.nmid = "nm0000243";
denzel.movies = IMDB.getMoviesForPerson(denzel.nmid);
denzel.n = nrow(denzel.movies);
#will = IMDB.searchPersonName("Will* Smith*");
#denzel = IMDB.searchPersonName("Denzel* Washington")
myWill.df = will.movies
WillRatings = myWill.df$metacritic
myDenzel.df = denzel.movies
denzelTop = myDenzel.df
DMovieRatings = myDenzel.df$metacritic
WGross = will.movies$millions
DGross = denzel.movies$millions
normalDiagnosticPlot(WGross)
normalDiagnosticPlot(DGross)
hist(WGross, main = "Histogram of Will Smith movie Grosses")
hist(DGross, main = "Histogram of Denzels movie Grosses")
plot(WGross, DGross)
View(denzel.movies)
View(will.movies)
library(dplyr)
will.nmid = "nm0000226";
will.movies = IMDB.getMoviesForPerson(will.nmid);
will.n = nrow(will.movies);
denzel.nmid = "nm0000243";
denzel.movies = IMDB.getMoviesForPerson(denzel.nmid);
denzel.n = nrow(denzel.movies);
#will = IMDB.searchPersonName("Will* Smith*");
#denzel = IMDB.searchPersonName("Denzel* Washington")
myWill.df = will.movies
WillRatings = myWill.df$metacritic
myDenzel.df = denzel.movies
denzelTop = myDenzel.df
DMovieRatings = myDenzel.df$metacritic
WGross = will.movies$millions
DGross = denzel.movies$millions
normalDiagnosticPlot(WGross)
normalDiagnosticPlot(DGross)
hist(WGross, main = "Histogram of Will Smith movie Grosses")
hist(DGross, main = "Histogram of Denzels movie Grosses")
t.test(WGross, DGross)
Wyear = myWill.df$year
Dyear = myDenzel.df$year
plot(WillRatings, Wyear)
reg.n = lm(Wyear ~ WillRatings)
abline(reg.n)
abline(reg.n)
plot(Dyear, DMovieRatings)
reg.n = lm(DMovieRatings ~ Dyear)
abline(reg.n)
abline(reg.n)
plot(Wyear, WGross)
reg.n = lm(WGross ~ Wyear, col = "red")
abline(reg.n)
abline(reg.n)
plot(Dyear, DGross)
reg.n = lm(DGross ~ Dyear)
abline(reg.n)
abline(reg.n)
summary(will$movies.50)
summary(denzel$movies.50)
willReviews = will.movies
Wreviews = willReviews$ratings
DenzelReviews = denzel.movies
DReviews = DenzelReviews$ratings
plot(Wreviews, type = "l", lwd = 2, col = "red")
plot(DReviews, type = "l", lwd = 2, col = "red")
hist(Wreviews)
hist(DReviews)
plot(Wreviews, DReviews)
willReviews = will.movies
Wreviews = willReviews$ratings
DenzelReviews = denzel.movies
DReviews = DenzelReviews$ratings
plot(Wreviews, type = "l", lwd = 2, col = "red")
plot(DReviews, type = "l", lwd = 2, col = "red")
hist(Wreviews)
hist(DReviews)
normalDiagnosticPlot(willReviews$ratings)
normalDiagnosticPlot(DenzelReviews$ratings)
t.test(Wreviews, DReviews)
library(gtsummary)
library(dplyr)
myWill.df = will.movies
WillYears= myWill.df$year
myDenzel.df = denzel.movies
denzelyear = myDenzel.df$year
plot(WillYears, denzelyear)
library(gtsummary)
library(dplyr)
myWill.df = will.movies
WillYears= myWill.df$year
myDenzel.df = denzel.movies
denzelyear = myDenzel.df$year
WGross = myWill.df$millions
DGross = myDenzel.df$millions
plot(WillYears, WGross)
reg.n = lm(WGross ~ WillYears)
abline(reg.n)
abline(reg.n)
plot(denzelyear, DGross)
reg.n = lm(DGross ~ denzelyear)
abline(reg.n)
abline(reg.n)
hist(WillYears)
hist(denzelyear)
total <- merge(myWill.df, myDenzel.df, by="year")
total
t.test(WGross, DGross)
#zero = myWill.df[,c("rating","millions")]
summary(myWill.df)
will.clean = removeNAsFromDataFrame(will.movies)
will.clean$budget.int = as.numeric(as.character(will.clean&budget))
will.clean = removeNAsFromDataFrame(will.movies)
path.project = "C:/Users/Galac/Desktop/git419/Stats419_FALL2020/Final/"
path.tables = paste0(path.project, "tables/")
createDirRecursive(path.tables)
file.correlation = paste0(path.tables, "Will-Smith-corr.tex")
myData = as.matrix(will.clean[,c("metacritic","millions","year")])
buildLatexCorrelationTable(myData,
rotateTable = FALSE,
width.table = .95,
myFile = file.correlation,
myNames = c("metacritic", "millions","year"),
myCaption = "will smith correlation")
will.clean = removeNAsFromDataFrame(will.movies)
path.project = "C:/Users/Galac/Desktop/git419/Stats419_FALL2020/Final/"
path.tables = paste0(path.project, "tables/")
createDirRecursive(path.tables)
file.correlation = paste0(path.tables, "Will-Smith-corr.tex")
myData = as.matrix(will.clean[,c("metacritic","millions","year")])
buildLatexCorrelationTable(myData,
rotateTable = FALSE,
width.table = .95,
myFile = file.correlation,
myNames = c("metacritic", "millions","year"),
myCaption = "will smith correlation")
will.clean = removeNAsFromDataFrame(will.movies)
path.project = "C:/Users/Galac/Desktop/git419/Stats419_FALL2020/Fina/"
path.tables = paste0(path.project, "tables/")
createDirRecursive(path.tables)
file.correlation = paste0(path.tables, "Will-Smith-corr.tex")
myData = as.matrix(will.clean[,c("metacritic","millions","year")])
buildLatexCorrelationTable(myData,
rotateTable = FALSE,
width.table = .95,
myFile = file.correlation,
myNames = c("metacritic", "millions","year"),
myCaption = "will smith correlation")
will.clean = removeNAsFromDataFrame(will.movies)
path.project = "C:/Users/Galac/Desktop/git419/Stats419_FALL2020/Fina/"
path.tables = paste0(path.project, "tables/")
createDirRecursive(path.tables)
file.correlation = paste0(path.tables, "Will-Smith-corr.tex")
myData = as.matrix(will.clean[,c("metacritic","millions","year")])
buildLatexCorrelationTable(myData,
rotateTable = FALSE,
width.table = .95,
myFile = file.correlation,
myNames = c("metacritic", "millions","year"),
myCaption = "will smith correlation")
will.clean = removeNAsFromDataFrame(will.movies)
path.project = "C:/Users/Galac/Desktop/git419/Stats419_FALL2020/Final/"
path.tables = paste0(path.project, "tables/")
createDirRecursive(path.tables)
file.correlation = paste0(path.tables, "Will-Smith-corr.te")
myData = as.matrix(will.clean[,c("metacritic","millions","year")])
buildLatexCorrelationTable(myData,
rotateTable = FALSE,
width.table = .95,
myFile = file.correlation,
myNames = c("metacritic", "millions","year"),
myCaption = "will smith correlation")
setwd("C:/Users/Galac/Desktop/git419/Stats419_FALL2020")
denzel.clean = removeNAsFromDataFrame(denzel.movies)
path.project = "C:/Users/Galac/Desktop/git419/Stats419_FALL2020/Final/"
path.tables = paste0(path.project, "tables/")
createDirRecursive(path.tables)
file.correlation = paste0(path.tables, "Denzel-corr.tex")
myData = as.matrix(will.clean[,c("metacritic","millions","year")])
buildLatexCorrelationTable(myData,
rotateTable = FALSE,
width.table = .95,
myFile = file.correlation,
myNames = c("metacritic", "millions","year"),
myCaption = "Denzel Washington correlation")
library(dplyr)
library(ggplot2)
library(gridextra)
install.packages("gridextra")
install.packages("gridExtra")
install.packages("gridExtra")
knitr::opts_chunk$set(echo = TRUE)
library(devtools);
library(humanVerseWSU);
path.github = "https://raw.githubusercontent.com/MonteShaffer/humanVerseWSU/master/";
include.me = paste0(path.github, "misc/functions-nlp.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-str.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-stack.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-pos.R");
source_url( include.me );
include.me = paste0(path.github, "humanVerseWSU/R/functions-encryption.R");
source_url( include.me );
include.me = paste0(path.github,"misc/functions-project-measure.R");
source_url( include.me);
path.to.nascent = "C:/Users/Alexander Nevsky/Dropbox/WSU-419/Fall 2020/__student_access__/unit_02_confirmatory_data_analysis/nascent/";
folder.nlp = "nlp/";
path.to.nlp = paste0(path.to.nascent, folder.nlp);
###### UPDATES TO dataframe subset function ######
# inflation adjustments for NA ... and improvements on subsetting
include.me = paste0(path.github, "humanVerseWSU/R/functions-dataframe.R");
source_url( include.me );
include.me = paste0(path.github, "humanVerseWSU/R/functions-inflation.R");
source_url( include.me );
# library(devtools);
# install_github("MonteShaffer/imdb/imdb"); # choose #3 to humanVerseWSU
# detach(package:imdb);
library(imdb);
packageVersion("imdb");  # ‘0.1.1’
# ?loadDataIMDB
install_github("MonteShaffer/imdb/imdb")
imdb::loadDataIMDB();
names(imdb.data);
humanVerseWSU::loadInflationData();
library(KernSmooth)
normalDiagnosticPlot = function(x,  normalityTest=TRUE,
showDensity=TRUE,
showNormal=TRUE,
showSDs=FALSE,
showAxis=TRUE
)
{
xx = na.omit(x);
x.stats = doStatsSummary(x);
# x.table = table(x);
# library(KernSmooth); # install.packages("KernSmooth", dependencies=TRUE);
# bin.count = dpih(xx);
# mybreaks = 100 * bin.count;
mxlim = c(x.stats$mean - 3.5 * x.stats$sd ,
x.stats$mean + 3.5 * x.stats$sd );
h = hist(xx, breaks="Sturges", plot=F);
mylim = c(0, max(h$counts));
myMain = paste0(  "Histogram (mean: ",
round(x.stats$mean,digits=3),
", sd: ",
round(x.stats$sd,digits=3),
")"
);
mxlab = "";
if(normalityTest)
{
isNormal = NULL;
if(x.stats$shapiro.is.normal$`0.10`) { isNormal = 0.10; }
if(x.stats$shapiro.is.normal$`0.05`) { isNormal = 0.05; }
if(x.stats$shapiro.is.normal$`0.01`) { isNormal = 0.01; }
isNormalResult = FALSE;
if(!is.null(isNormal)) { isNormalResult = TRUE;}
if(is.null(isNormal)) { isNormal = 0.05;}
mxlab = paste0("Shapiro Normality test at (alpha = ",
isNormal, ") is ... ",isNormalResult);
}
### Histogram
hist(xx, breaks="Sturges",  xlim=mxlim, ylim=mylim,
xlab=mxlab, xaxt='n', main=myMain);
if(showDensity)
{
par(new=T); # overlay
### Density Plot (remember first reading?)
plot( density(xx, kernel="epanechnikov") ,
xlim=mxlim,
main="",
xlab="",
ylab="",
xaxt='n',
yaxt='n'
);
}
if(showNormal)
{
par(new=T); # overlay
### Normal Curve
xt = seq(-3.5,3.5, length=100);
yt = dnorm(xt);
plot( xt, yt,
type="l",
lwd=2,
col = "red",
axes=F,
xlab="",
ylab=""
);
}
if(showSDs)
{
### vertical lines at sd's of data ...
abline(v=x.stats$mean,lwd=4,col="blue");
abline(v=x.stats$mean - 1 * x.stats$sd , col="green",lwd=3);
abline(v=x.stats$mean + 1 * x.stats$sd , col="green",lwd=3);
abline(v=x.stats$mean - 2 * x.stats$sd , col="green",lwd=2);
abline(v=x.stats$mean + 2 * x.stats$sd , col="green",lwd=2);
abline(v=x.stats$mean - 3 * x.stats$sd , col="green",lwd=1);
abline(v=x.stats$mean + 3 * x.stats$sd , col="green",lwd=1);
}
if(showAxis)
{
### axis labels showing the ability to use expression
axis(1, at = -3:3, labels = c( expression("-3"~hat(sigma) ), expression("-2"~sigma ), expression("-1"~hat(s) ), expression(bar(x)), expression("1"~hat(s) ), "2s", c( expression("3"~hat(sigma) ))) );
#axis(1, at = -3:3, labels = c("-3s", "-2s", "-1s", "hat(mu)", "1s", "2s", "3s"))
}
}
library(dplyr)
library(ggplot2)
library(gridextra)
install.packages(gridExtra)
install.packages("gridExtra")
